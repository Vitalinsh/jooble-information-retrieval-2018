{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "WKiM6bqhdMNC",
    "outputId": "3248c353-a855-4250-a40f-c47512b67a91"
   },
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "wT4lwxZDcnvV",
    "outputId": "0243b34e-9081-408e-b9dc-b8850f65f696"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional, Dropout\n",
    "from keras.layers import SpatialDropout1D, Conv1D, MaxPooling1D\n",
    "from gensim.models import Word2Vec\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l2\n",
    "import seaborn as sns\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from google.colab import files\n",
    " \n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "zILl-394dJvO",
    "outputId": "97a61f46-c029-42ca-f63d-381ea3475476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHhSXgVvcnvb"
   },
   "outputs": [],
   "source": [
    "w2v_path = os.path.join(\"/content/gdrive/My Drive/\", \"Colab Notebooks/ruwikiruscorpora-nobigrams_upos_skipgram_300_5_2018.vec.gz\")\n",
    "hh_data_path = os.path.join(\"/content/gdrive/My Drive/\", \"Colab Notebooks/hh_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "colab_type": "code",
    "id": "sUQx_qMEcnve",
    "outputId": "20b65768-a6b4-47cc-8a27-25ab36b70afd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25223 entries, 0 to 25222\n",
      "Data columns (total 26 columns):\n",
      "id                            25223 non-null int64\n",
      "lang_text                     25223 non-null object\n",
      "lang_title                    25223 non-null object\n",
      "profarea_names                25223 non-null object\n",
      "requirement                   24322 non-null object\n",
      "requirement_lemmas            24321 non-null object\n",
      "requirement_lemmas_tags       24321 non-null object\n",
      "requirement_norm              24321 non-null object\n",
      "requirement_tokens            24321 non-null object\n",
      "responsibility                23890 non-null object\n",
      "responsibility_lemmas         23889 non-null object\n",
      "responsibility_lemmas_tags    23889 non-null object\n",
      "responsibility_norm           23889 non-null object\n",
      "responsibility_tokens         23889 non-null object\n",
      "specializations               25223 non-null object\n",
      "text                          25223 non-null object\n",
      "text_lemmas                   25223 non-null object\n",
      "text_lemmas_tags              25223 non-null object\n",
      "text_normalized               25223 non-null object\n",
      "text_tokens                   25223 non-null object\n",
      "title                         25223 non-null object\n",
      "title_lemmas                  22549 non-null object\n",
      "title_lemmas_tags             22549 non-null object\n",
      "title_normalized              22555 non-null object\n",
      "title_tokens                  22555 non-null object\n",
      "url                           25223 non-null object\n",
      "dtypes: int64(1), object(25)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_hh = pd.read_csv(hh_data_path, sep=\"\\t\")\n",
    "dataset_hh = dataset_hh.loc[dataset_hh[\"lang_text\"] == \"russian\"]\n",
    "#dataset_hh.drop(dataset_hh.index[dataset_hh[\"lang_text\"] == \"english\"], inplace=True)\n",
    "dataset_hh.reset_index(drop=True, inplace=True)\n",
    "dataset_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "dKWtnMAKi0Ef",
    "outputId": "f9bdb355-0402-4fbc-c133-b24433d969ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final size of dataset = 17250\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17250 entries, 0 to 17249\n",
      "Data columns (total 26 columns):\n",
      "id                            17250 non-null int64\n",
      "lang_text                     17250 non-null object\n",
      "lang_title                    17250 non-null object\n",
      "profarea_names                17250 non-null object\n",
      "requirement                   16763 non-null object\n",
      "requirement_lemmas            16762 non-null object\n",
      "requirement_lemmas_tags       16762 non-null object\n",
      "requirement_norm              16762 non-null object\n",
      "requirement_tokens            16762 non-null object\n",
      "responsibility                16481 non-null object\n",
      "responsibility_lemmas         16480 non-null object\n",
      "responsibility_lemmas_tags    16480 non-null object\n",
      "responsibility_norm           16480 non-null object\n",
      "responsibility_tokens         16480 non-null object\n",
      "specializations               17250 non-null object\n",
      "text                          17250 non-null object\n",
      "text_lemmas                   17250 non-null object\n",
      "text_lemmas_tags              17250 non-null object\n",
      "text_normalized               17250 non-null object\n",
      "text_tokens                   17250 non-null object\n",
      "title                         17250 non-null object\n",
      "title_lemmas                  15476 non-null object\n",
      "title_lemmas_tags             15476 non-null object\n",
      "title_normalized              15479 non-null object\n",
      "title_tokens                  15479 non-null object\n",
      "url                           17250 non-null object\n",
      "dtypes: int64(1), object(25)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_hh.drop_duplicates([\"text\"], inplace=True)\n",
    "print(\"Final size of dataset =\", len(dataset_hh))\n",
    "dataset_hh.reset_index(drop=True, inplace=True)\n",
    "dataset_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "MRIxkoDzcnvm",
    "outputId": "17a9cdfc-c9d9-4310-d497-e8d41b0a7a19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang_text</th>\n",
       "      <th>lang_title</th>\n",
       "      <th>profarea_names</th>\n",
       "      <th>requirement</th>\n",
       "      <th>requirement_lemmas</th>\n",
       "      <th>requirement_lemmas_tags</th>\n",
       "      <th>requirement_norm</th>\n",
       "      <th>requirement_tokens</th>\n",
       "      <th>responsibility</th>\n",
       "      <th>responsibility_lemmas</th>\n",
       "      <th>responsibility_lemmas_tags</th>\n",
       "      <th>responsibility_norm</th>\n",
       "      <th>responsibility_tokens</th>\n",
       "      <th>specializations</th>\n",
       "      <th>text</th>\n",
       "      <th>text_lemmas</th>\n",
       "      <th>text_lemmas_tags</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>title</th>\n",
       "      <th>title_lemmas</th>\n",
       "      <th>title_lemmas_tags</th>\n",
       "      <th>title_normalized</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28109665</td>\n",
       "      <td>russian</td>\n",
       "      <td>russian</td>\n",
       "      <td>['Административный персонал', 'Продажи']</td>\n",
       "      <td>Высшее образование. Опыт работы в организации ...</td>\n",
       "      <td>высший образование опыт работа организация кли...</td>\n",
       "      <td>высший_ADJ образование_NOUN опыт_NOUN работа_N...</td>\n",
       "      <td>высш образован оп работ организац клиентск сер...</td>\n",
       "      <td>высшее образование опыт работы организации кли...</td>\n",
       "      <td>Организация обучения сотрудников подразделения...</td>\n",
       "      <td>организация обучение сотрудник подразделение о...</td>\n",
       "      <td>организация_NOUN обучение_NOUN сотрудник_NOUN ...</td>\n",
       "      <td>организац обучен сотрудник подразделен организ...</td>\n",
       "      <td>организация обучения сотрудников подразделения...</td>\n",
       "      <td>['Ресепшен', 'Менеджер по работе с клиентами']</td>\n",
       "      <td>&lt;p&gt;Группа компаний «Три-З» занимает лидирующие...</td>\n",
       "      <td>группа компания занимать лидировать позиция ро...</td>\n",
       "      <td>группа_NOUN компания_NOUN занимать_VERB лидиро...</td>\n",
       "      <td>групп компан занима лидир позиц российск рынк ...</td>\n",
       "      <td>группа компаний занимает лидирующие позиции ро...</td>\n",
       "      <td>Начальник отдела клиентского сервиса</td>\n",
       "      <td>начальник отдел клиентский сервис</td>\n",
       "      <td>начальник_NOUN отдел_NOUN клиентский_ADJ серви...</td>\n",
       "      <td>начальник отдел клиентск сервис</td>\n",
       "      <td>начальник отдела клиентского сервиса</td>\n",
       "      <td>https://api.hh.ru/vacancies/28109665?host=hh.ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29258242</td>\n",
       "      <td>russian</td>\n",
       "      <td>russian</td>\n",
       "      <td>['Закупки', 'Закупки', 'Закупки', 'Продажи', '...</td>\n",
       "      <td>Нам нужен человек обязательно с опытом работы ...</td>\n",
       "      <td>мы нужный человек обязательно опыт работа мага...</td>\n",
       "      <td>мы_PRON нужный_ADJ человек_NOUN обязательно_AD...</td>\n",
       "      <td>нам нуж человек обязательн опыт работ магазин ...</td>\n",
       "      <td>нам нужен человек обязательно опытом работы ма...</td>\n",
       "      <td>Скупать товары народного потребления у входящи...</td>\n",
       "      <td>скупать товар народный потребление входить кли...</td>\n",
       "      <td>скупать_VERB товар_NOUN народный_ADJ потреблен...</td>\n",
       "      <td>скупа товар народн потреблен входя клиент прод...</td>\n",
       "      <td>скупать товары народного потребления входящих ...</td>\n",
       "      <td>['Электроника, фото, видео', 'Электротехническ...</td>\n",
       "      <td>&lt;p&gt;Привет, мы – компания СКУПКА.&lt;br /&gt;Мы скупа...</td>\n",
       "      <td>привет компания скупавать продавать различный ...</td>\n",
       "      <td>привет_VERB компания_NOUN скупавать_VERB прода...</td>\n",
       "      <td>привет компан скупа прода различн товар электр...</td>\n",
       "      <td>привет компания скупаем продаем различные това...</td>\n",
       "      <td>Менеджер по продажам</td>\n",
       "      <td>менеджер продажа</td>\n",
       "      <td>менеджер_NOUN продажа_NOUN</td>\n",
       "      <td>менеджер продаж</td>\n",
       "      <td>менеджер продажам</td>\n",
       "      <td>https://api.hh.ru/vacancies/29258242?host=hh.ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28944166</td>\n",
       "      <td>russian</td>\n",
       "      <td>russian</td>\n",
       "      <td>['Домашний персонал', 'Домашний персонал', 'На...</td>\n",
       "      <td>Опыт работы педагогом в детских дошкольных учр...</td>\n",
       "      <td>опыт работа педагог детский дошкольный учреждение</td>\n",
       "      <td>опыт_NOUN работа_NOUN педагог_NOUN детский_ADJ...</td>\n",
       "      <td>оп работ педагог детск дошкольн учрежден</td>\n",
       "      <td>опыт работы педагогом детских дошкольных учреж...</td>\n",
       "      <td>Проведение занятий с детьми от 8 мес. до 7 лет...</td>\n",
       "      <td>проведение занятие ребенок месяц лета методика...</td>\n",
       "      <td>проведение_NOUN занятие_NOUN ребенок_NUM месяц...</td>\n",
       "      <td>проведен занят детьм мес лет методик консульти...</td>\n",
       "      <td>проведение занятий детьми мес лет методикам ко...</td>\n",
       "      <td>['Воспитатель, Гувернантка, Няня', 'Репетитор'...</td>\n",
       "      <td>&lt;p&gt;«Бэби-клуб Матвеевский» приглашает педагога...</td>\n",
       "      <td>матвеевский приглашать педагог ранний развитие...</td>\n",
       "      <td>матвеевский_NOUN приглашать_VERB педагог_NOUN ...</td>\n",
       "      <td>матвеевск приглаша педагог ран развит бережн р...</td>\n",
       "      <td>матвеевский приглашает педагога раннему развит...</td>\n",
       "      <td>Специалист (педагог) по раннему развитию</td>\n",
       "      <td>специалист педагог ранний развитие</td>\n",
       "      <td>специалист_NOUN педагог_NOUN ранний_ADJ развит...</td>\n",
       "      <td>специалист педагог ран развит</td>\n",
       "      <td>специалист педагог раннему развитию</td>\n",
       "      <td>https://api.hh.ru/vacancies/28944166?host=care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29258121</td>\n",
       "      <td>russian</td>\n",
       "      <td>russian</td>\n",
       "      <td>['Наука, образование', 'Наука, образование', '...</td>\n",
       "      <td>Творческий подход, командный дух, инициативу и...</td>\n",
       "      <td>творческий подход командный дух инициатива улы...</td>\n",
       "      <td>творческий_ADJ подход_NOUN командный_ADJ дух_N...</td>\n",
       "      <td>творческ подход командн дух инициатив улыбк тр...</td>\n",
       "      <td>творческий подход командный дух инициативу улы...</td>\n",
       "      <td>Участие в общественно-маркетинговой жизни Школы.</td>\n",
       "      <td>участие жизнь школа</td>\n",
       "      <td>участие_NOUN жизнь_NOUN школа_NOUN</td>\n",
       "      <td>участ жизн школ</td>\n",
       "      <td>участие жизни школы</td>\n",
       "      <td>['Информатика, Информационные системы', 'Гуман...</td>\n",
       "      <td>&lt;p&gt;Впервые в Биробиджане школа скорочтения и р...</td>\n",
       "      <td>впервые биробиджанин школа скорочтения развити...</td>\n",
       "      <td>впервые_ADV биробиджанин_NOUN школа_NOUN скоро...</td>\n",
       "      <td>вперв биробиджан школ скорочтен развит интелле...</td>\n",
       "      <td>впервые биробиджане школа скорочтения развития...</td>\n",
       "      <td>Педагог</td>\n",
       "      <td>педагог</td>\n",
       "      <td>педагог_NOUN</td>\n",
       "      <td>педагог</td>\n",
       "      <td>педагог</td>\n",
       "      <td>https://api.hh.ru/vacancies/29258121?host=care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28840602</td>\n",
       "      <td>russian</td>\n",
       "      <td>russian</td>\n",
       "      <td>['Наука, образование', 'Наука, образование', '...</td>\n",
       "      <td>Высшее образование/бакалавриат. - Коммуникацио...</td>\n",
       "      <td>высший коммуникационный навык высокий ориентац...</td>\n",
       "      <td>высший_ADJ коммуникационный_ADJ навык_NOUN выс...</td>\n",
       "      <td>высш коммуникацион навык высок ориентац ученик...</td>\n",
       "      <td>высшее коммуникационные навыки высокая ориента...</td>\n",
       "      <td>Преподавание курса Скорочтение и развитие инте...</td>\n",
       "      <td>преподавание курс скорочтений развитие интелле...</td>\n",
       "      <td>преподавание_NOUN курс_NOUN скорочтений_NOUN р...</td>\n",
       "      <td>преподаван курс скорочтен развит интеллект шко...</td>\n",
       "      <td>преподавание курса скорочтение развитие интелл...</td>\n",
       "      <td>['Гуманитарные науки', 'Начальный уровень, Мал...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Школа скорочтение и развития интелл...</td>\n",
       "      <td>школа скорочтений развитие интеллект междунаро...</td>\n",
       "      <td>школа_NOUN скорочтений_NOUN развитие_NOUN инте...</td>\n",
       "      <td>школ скорочтен развит интеллект международн се...</td>\n",
       "      <td>школа скорочтение развития интеллекта междунар...</td>\n",
       "      <td>Педагог-психолог</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.hh.ru/vacancies/28840602?host=care...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id lang_text lang_title  \\\n",
       "0  28109665   russian    russian   \n",
       "1  29258242   russian    russian   \n",
       "2  28944166   russian    russian   \n",
       "3  29258121   russian    russian   \n",
       "4  28840602   russian    russian   \n",
       "\n",
       "                                      profarea_names  \\\n",
       "0           ['Административный персонал', 'Продажи']   \n",
       "1  ['Закупки', 'Закупки', 'Закупки', 'Продажи', '...   \n",
       "2  ['Домашний персонал', 'Домашний персонал', 'На...   \n",
       "3  ['Наука, образование', 'Наука, образование', '...   \n",
       "4  ['Наука, образование', 'Наука, образование', '...   \n",
       "\n",
       "                                         requirement  \\\n",
       "0  Высшее образование. Опыт работы в организации ...   \n",
       "1  Нам нужен человек обязательно с опытом работы ...   \n",
       "2  Опыт работы педагогом в детских дошкольных учр...   \n",
       "3  Творческий подход, командный дух, инициативу и...   \n",
       "4  Высшее образование/бакалавриат. - Коммуникацио...   \n",
       "\n",
       "                                  requirement_lemmas  \\\n",
       "0  высший образование опыт работа организация кли...   \n",
       "1  мы нужный человек обязательно опыт работа мага...   \n",
       "2  опыт работа педагог детский дошкольный учреждение   \n",
       "3  творческий подход командный дух инициатива улы...   \n",
       "4  высший коммуникационный навык высокий ориентац...   \n",
       "\n",
       "                             requirement_lemmas_tags  \\\n",
       "0  высший_ADJ образование_NOUN опыт_NOUN работа_N...   \n",
       "1  мы_PRON нужный_ADJ человек_NOUN обязательно_AD...   \n",
       "2  опыт_NOUN работа_NOUN педагог_NOUN детский_ADJ...   \n",
       "3  творческий_ADJ подход_NOUN командный_ADJ дух_N...   \n",
       "4  высший_ADJ коммуникационный_ADJ навык_NOUN выс...   \n",
       "\n",
       "                                    requirement_norm  \\\n",
       "0  высш образован оп работ организац клиентск сер...   \n",
       "1  нам нуж человек обязательн опыт работ магазин ...   \n",
       "2           оп работ педагог детск дошкольн учрежден   \n",
       "3  творческ подход командн дух инициатив улыбк тр...   \n",
       "4  высш коммуникацион навык высок ориентац ученик...   \n",
       "\n",
       "                                  requirement_tokens  \\\n",
       "0  высшее образование опыт работы организации кли...   \n",
       "1  нам нужен человек обязательно опытом работы ма...   \n",
       "2  опыт работы педагогом детских дошкольных учреж...   \n",
       "3  творческий подход командный дух инициативу улы...   \n",
       "4  высшее коммуникационные навыки высокая ориента...   \n",
       "\n",
       "                                      responsibility  \\\n",
       "0  Организация обучения сотрудников подразделения...   \n",
       "1  Скупать товары народного потребления у входящи...   \n",
       "2  Проведение занятий с детьми от 8 мес. до 7 лет...   \n",
       "3   Участие в общественно-маркетинговой жизни Школы.   \n",
       "4  Преподавание курса Скорочтение и развитие инте...   \n",
       "\n",
       "                               responsibility_lemmas  \\\n",
       "0  организация обучение сотрудник подразделение о...   \n",
       "1  скупать товар народный потребление входить кли...   \n",
       "2  проведение занятие ребенок месяц лета методика...   \n",
       "3                                участие жизнь школа   \n",
       "4  преподавание курс скорочтений развитие интелле...   \n",
       "\n",
       "                          responsibility_lemmas_tags  \\\n",
       "0  организация_NOUN обучение_NOUN сотрудник_NOUN ...   \n",
       "1  скупать_VERB товар_NOUN народный_ADJ потреблен...   \n",
       "2  проведение_NOUN занятие_NOUN ребенок_NUM месяц...   \n",
       "3                 участие_NOUN жизнь_NOUN школа_NOUN   \n",
       "4  преподавание_NOUN курс_NOUN скорочтений_NOUN р...   \n",
       "\n",
       "                                 responsibility_norm  \\\n",
       "0  организац обучен сотрудник подразделен организ...   \n",
       "1  скупа товар народн потреблен входя клиент прод...   \n",
       "2  проведен занят детьм мес лет методик консульти...   \n",
       "3                                    участ жизн школ   \n",
       "4  преподаван курс скорочтен развит интеллект шко...   \n",
       "\n",
       "                               responsibility_tokens  \\\n",
       "0  организация обучения сотрудников подразделения...   \n",
       "1  скупать товары народного потребления входящих ...   \n",
       "2  проведение занятий детьми мес лет методикам ко...   \n",
       "3                                участие жизни школы   \n",
       "4  преподавание курса скорочтение развитие интелл...   \n",
       "\n",
       "                                     specializations  \\\n",
       "0     ['Ресепшен', 'Менеджер по работе с клиентами']   \n",
       "1  ['Электроника, фото, видео', 'Электротехническ...   \n",
       "2  ['Воспитатель, Гувернантка, Няня', 'Репетитор'...   \n",
       "3  ['Информатика, Информационные системы', 'Гуман...   \n",
       "4  ['Гуманитарные науки', 'Начальный уровень, Мал...   \n",
       "\n",
       "                                                text  \\\n",
       "0  <p>Группа компаний «Три-З» занимает лидирующие...   \n",
       "1  <p>Привет, мы – компания СКУПКА.<br />Мы скупа...   \n",
       "2  <p>«Бэби-клуб Матвеевский» приглашает педагога...   \n",
       "3  <p>Впервые в Биробиджане школа скорочтения и р...   \n",
       "4  <p><strong>Школа скорочтение и развития интелл...   \n",
       "\n",
       "                                         text_lemmas  \\\n",
       "0  группа компания занимать лидировать позиция ро...   \n",
       "1  привет компания скупавать продавать различный ...   \n",
       "2  матвеевский приглашать педагог ранний развитие...   \n",
       "3  впервые биробиджанин школа скорочтения развити...   \n",
       "4  школа скорочтений развитие интеллект междунаро...   \n",
       "\n",
       "                                    text_lemmas_tags  \\\n",
       "0  группа_NOUN компания_NOUN занимать_VERB лидиро...   \n",
       "1  привет_VERB компания_NOUN скупавать_VERB прода...   \n",
       "2  матвеевский_NOUN приглашать_VERB педагог_NOUN ...   \n",
       "3  впервые_ADV биробиджанин_NOUN школа_NOUN скоро...   \n",
       "4  школа_NOUN скорочтений_NOUN развитие_NOUN инте...   \n",
       "\n",
       "                                     text_normalized  \\\n",
       "0  групп компан занима лидир позиц российск рынк ...   \n",
       "1  привет компан скупа прода различн товар электр...   \n",
       "2  матвеевск приглаша педагог ран развит бережн р...   \n",
       "3  вперв биробиджан школ скорочтен развит интелле...   \n",
       "4  школ скорочтен развит интеллект международн се...   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  группа компаний занимает лидирующие позиции ро...   \n",
       "1  привет компания скупаем продаем различные това...   \n",
       "2  матвеевский приглашает педагога раннему развит...   \n",
       "3  впервые биробиджане школа скорочтения развития...   \n",
       "4  школа скорочтение развития интеллекта междунар...   \n",
       "\n",
       "                                      title  \\\n",
       "0      Начальник отдела клиентского сервиса   \n",
       "1                      Менеджер по продажам   \n",
       "2  Специалист (педагог) по раннему развитию   \n",
       "3                                   Педагог   \n",
       "4                          Педагог-психолог   \n",
       "\n",
       "                         title_lemmas  \\\n",
       "0   начальник отдел клиентский сервис   \n",
       "1                    менеджер продажа   \n",
       "2  специалист педагог ранний развитие   \n",
       "3                             педагог   \n",
       "4                                 NaN   \n",
       "\n",
       "                                   title_lemmas_tags  \\\n",
       "0  начальник_NOUN отдел_NOUN клиентский_ADJ серви...   \n",
       "1                         менеджер_NOUN продажа_NOUN   \n",
       "2  специалист_NOUN педагог_NOUN ранний_ADJ развит...   \n",
       "3                                       педагог_NOUN   \n",
       "4                                                NaN   \n",
       "\n",
       "                  title_normalized                          title_tokens  \\\n",
       "0  начальник отдел клиентск сервис  начальник отдела клиентского сервиса   \n",
       "1                  менеджер продаж                     менеджер продажам   \n",
       "2    специалист педагог ран развит   специалист педагог раннему развитию   \n",
       "3                          педагог                               педагог   \n",
       "4                              NaN                                   NaN   \n",
       "\n",
       "                                                 url  \n",
       "0    https://api.hh.ru/vacancies/28109665?host=hh.ua  \n",
       "1    https://api.hh.ru/vacancies/29258242?host=hh.ua  \n",
       "2  https://api.hh.ru/vacancies/28944166?host=care...  \n",
       "3  https://api.hh.ru/vacancies/29258121?host=care...  \n",
       "4  https://api.hh.ru/vacancies/28840602?host=care...  "
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvTcYfW9cnv3"
   },
   "source": [
    "### Prapare data to rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pcgnmOXwcnv4"
   },
   "outputs": [],
   "source": [
    "vectorizer = KeyedVectors.load_word2vec_format(w2v_path, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "1NO23HEql_Lt",
    "outputId": "14553f4d-8199-41cd-b556-1ba7cf0358be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2cd664d6-e665-497b-bfcc-9d4c279b1162\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-2cd664d6-e665-497b-bfcc-9d4c279b1162\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vectorizer_tfidf.dat to vectorizer_tfidf (1).dat\n"
     ]
    }
   ],
   "source": [
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "gARFfhqZmKj_",
    "outputId": "0088d7d5-1483-4c2b-a64e-ed00ee0c23b2"
   },
   "outputs": [],
   "source": [
    "with open(\"vectorizer_tfidf (1).dat\", \"rb\") as inf:\n",
    "  vectorizer_tfidf = pickle.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3-v5JoSitMJp",
    "outputId": "f25f6aab-2816-49d5-ff30-ae20d0b77e91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.64 s, sys: 53.5 ms, total: 6.69 s\n",
      "Wall time: 6.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = [text for text in dataset_hh.loc[:, \"text_normalized\"]]\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(min_df=1, ngram_range=(1, 2),  lowercase=False)\n",
    "vectorizer_tfidf.fit(corpus)\n",
    "#ngram_range=(1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EV4Yjfszojst"
   },
   "outputs": [],
   "source": [
    "corpus = [text for text in dataset_hh.loc[:, \"text_normalized\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "neiWfmlev1LK",
    "outputId": "295063d9-ba60-40a2-b56f-421086135d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109782\n",
      "area order\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(vectorizer_tfidf.get_feature_names()))\n",
    "print(vectorizer_tfidf.get_feature_names()[10001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpiwbYqk8KSB"
   },
   "outputs": [],
   "source": [
    "with open(\"vectorizer_tfidf_hh.dat\", \"wb\") as ouf:\n",
    "  pickle.dump(vectorizer_tfidf, ouf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgqi7MVj8FP8"
   },
   "outputs": [],
   "source": [
    "files.download(\"vectorizer_tfidf_hh.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMH7eStIMtAH"
   },
   "source": [
    "### Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "M_cl2LhRcnv8",
    "outputId": "58f10056-7a7c-4960-ea12-da64cd1ebc87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels number: 28\n",
      "Labels: ['информационные технологии, интернет, телеком', 'строительство, недвижимость', 'страхование', 'спортивные клубы, фитнес, салоны красоты', 'высший менеджмент', 'маркетинг, реклама, pr', 'медицина, фармацевтика', 'консультирование', 'бухгалтерия, управленческий учет, финансы предприятия', 'добыча сырья', 'государственная служба, некоммерческие организации', 'рабочий персонал', 'наука, образование', 'закупки', 'автомобильный бизнес', 'управление персоналом, тренинги', 'транспорт, логистика', 'производство', 'туризм, гостиницы, рестораны', 'продажи', 'юристы', 'банки, инвестиции, лизинг', 'административный персонал', 'начало карьеры, студенты', 'домашний персонал', 'безопасность', 'инсталляция и сервис', 'искусство, развлечения, масс-медиа']\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for i, row in dataset_hh.iterrows():\n",
    "    specs = row[\"profarea_names\"].lower()\n",
    "    specs = specs.split(\"', \") \n",
    "    for spec in specs: \n",
    "        spec = re.sub('[\\[\\'\\]]', '', spec)\n",
    "        labels.append(spec.strip())\n",
    "\n",
    "labels = list(set(labels))\n",
    "\n",
    "print(\"Labels number:\", len(labels))\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bS9-IFc7-crN"
   },
   "outputs": [],
   "source": [
    "labels = ['информационные технологии, интернет, телеком', 'строительство, недвижимость', 'спортивные клубы, фитнес, салоны красоты', 'маркетинг, реклама, pr', 'медицина, фармацевтика', 'консультирование', 'бухгалтерия, управленческий учет, финансы предприятия', 'рабочий персонал', 'наука, образование', 'автомобильный бизнес', 'управление персоналом, тренинги', 'транспорт, логистика', 'производство', 'туризм, гостиницы, рестораны', 'продажи', 'юристы', 'банки, инвестиции, лизинг', 'административный персонал', 'начало карьеры, студенты', 'искусство, развлечения, масс-медиа']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeCgu0RfcnwH"
   },
   "outputs": [],
   "source": [
    "def vectorize_text(text, vectorizer, max_len):\n",
    "    \"\"\"\n",
    "    :param str text: normalized text\n",
    "    :param Word2Vec vectorizer:\n",
    "    :param int max_len:\n",
    "    :return np.array text_vect: of shape like (1, max_len, 100)\n",
    "    \"\"\"\n",
    "    text_vect = []\n",
    "    words = text.split(\" \")\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vect = vectorizer.word_vec(word)\n",
    "            text_vect.append(word_vect)\n",
    "        except KeyError:\n",
    "            None\n",
    "      \n",
    "    np.array(text_vect)\n",
    "    text_vect = np.reshape(text_vect, (1, -1, 100))\n",
    "    text_vect = sequence.pad_sequences(text_vect, maxlen=max_len, dtype='float')\n",
    "            \n",
    "    return text_vect\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YY2NUFAA0IUR"
   },
   "source": [
    "### Prepare X and Y using tf-idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "sej17mLo0Vnp",
    "outputId": "225a127e-c90a-420a-af18-23ab7e9018d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.66 s, sys: 11.7 ms, total: 4.67 s\n",
      "Wall time: 4.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Try using tf-idf to classification\n",
    "X = vectorizer_tfidf.transform(corpus)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HptzipW90ICn"
   },
   "outputs": [],
   "source": [
    "n_classes = len(labels)\n",
    "n_examples = len(dataset_hh)\n",
    "Y = np.zeros((n_examples, n_classes))\n",
    "\n",
    "for i, row in dataset_hh.iterrows():     \n",
    "    specs = row[\"profarea_names\"].lower() \n",
    "    specs = specs.split(\"', \") \n",
    "    for spec in specs: \n",
    "        spec = re.sub('[\\[\\'\\]]', '', spec)\n",
    "        if spec in labels:\n",
    "          pos = labels.index(spec.strip())\n",
    "        Y[i][pos] = 1\n",
    "        \n",
    "assert(X.shape[0] == Y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jn1p9aiKM4CI"
   },
   "source": [
    "### Prepare X and Y using mean word2vec for document weighted by tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1823
    },
    "colab_type": "code",
    "id": "NEa5v7qxM3j-",
    "outputId": "6f9c9063-d9ac-41b4-a093-73dc92084f61"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dict_tfidf = vectorizer_tfidf.get_feature_names()\n",
    "\n",
    "n_classes = len(labels)\n",
    "n_examples = len(dataset_hh)\n",
    "X = []\n",
    "Y = np.zeros((n_examples, n_classes))\n",
    "for i, row in dataset_hh.iterrows():\n",
    "    X.append([])\n",
    "    text = row[\"text_lemmas_tags\"]\n",
    "    words = text.split(\" \")\n",
    "    text_tfidf = vectorizer_tfidf.transform([text])\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vec = vectorizer.word_vec(word)\n",
    "            if word in dict_tfidf:\n",
    "              pos = dict_tfidf.index(word)\n",
    "              weight = text_tfidf[0, pos]\n",
    "              word_vec = word_vec * weight\n",
    "            \n",
    "            X[i].append(word_vec)\n",
    "        except KeyError:\n",
    "            None\n",
    "     \n",
    "    \n",
    "    specs = row[\"profarea_names\"].lower() \n",
    "    specs = specs.split(\"', \") \n",
    "    for spec in specs: \n",
    "        spec = re.sub('[\\[\\'\\]]', '', spec)\n",
    "        pos = labels.index(spec.strip())\n",
    "        Y[i][pos] = 1\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "      print(\"Document number -\", i)\n",
    "        \n",
    "assert(len(X) == len(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "SqyBq2YEQsaV",
    "outputId": "21fc6a13-58d2-4bca-ac75-cc0654952c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10521\n",
      "(10521, 28)\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBXRwF2Wz3e3"
   },
   "source": [
    "### Prepare X and Y using word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8-aKhDccnwK"
   },
   "outputs": [],
   "source": [
    "\n",
    "n_classes = len(labels)\n",
    "n_examples = len(dataset_hh)\n",
    "X = []\n",
    "Y = np.zeros((n_examples, n_classes))\n",
    "for i, row in dataset_hh.iterrows():\n",
    "    X.append([])\n",
    "    words = row[\"text_lemmas_tags\"].split(\" \")\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vec = vectorizer.word_vec(word)\n",
    "            X[i].append(word_vec)\n",
    "        except KeyError:\n",
    "            None\n",
    "     \n",
    "    \n",
    "    specs = row[\"profarea_names\"].lower() \n",
    "    specs = specs.split(\"', \") \n",
    "    for spec in specs: \n",
    "        spec = re.sub('[\\[\\'\\]]', '', spec)\n",
    "        pos = labels.index(spec.strip())\n",
    "        Y[i][pos] = 1\n",
    "        \n",
    "assert(len(X) == len(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "XMYokp3PcnwN",
    "outputId": "08a67c60-e529-4295-c041-e2a18784a50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max len = 777\n",
      "Max len edited= 300\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(i) for i in X])\n",
    "print(\"Max len =\", max_len)\n",
    "max_len = 300\n",
    "print(\"Max len edited=\", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3GFgIg1gU4y"
   },
   "outputs": [],
   "source": [
    "#X = sequence.pad_sequences(X, maxlen=max_len, dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "_ko-wTJscnwd",
    "outputId": "12f66b5b-ae3c-454a-ff15-46ad87336de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22556\n",
      "(22556, 28)\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2o6qYiFcnwz"
   },
   "outputs": [],
   "source": [
    "def get_classes(y_one_hot, labels, threshold=0.5):\n",
    "    \"\"\"\n",
    "    :param np.array y_one_hot: shape like (1, n_classes)\n",
    "    :param list of str labels:\n",
    "    :return list of str classes: \n",
    "    \"\"\"\n",
    "    classes = []\n",
    "    y_rounded = np.zeros(y_one_hot.shape)\n",
    "    y_rounded[y_one_hot > threshold] = 1\n",
    "    for i in range(len(labels)):\n",
    "        if y_rounded[0][i] == 1:\n",
    "            classes.append(labels[i])\n",
    "            \n",
    "    return classes\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-A29Qz40otf"
   },
   "source": [
    "### Calculate counts for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "colab_type": "code",
    "id": "zXJmpTrzcnw6",
    "outputId": "e52374ab-3b68-43d6-daec-143082cb1234",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Label информационные технологии, интернет, телеком appears 2463.0 times\n",
      "1  Label строительство, недвижимость appears 1276.0 times\n",
      "2  Label страхование appears 146.0 times\n",
      "3  Label спортивные клубы, фитнес, салоны красоты appears 416.0 times\n",
      "4  Label высший менеджмент appears 288.0 times\n",
      "5  Label маркетинг, реклама, pr appears 1528.0 times\n",
      "6  Label медицина, фармацевтика appears 777.0 times\n",
      "7  Label консультирование appears 849.0 times\n",
      "8  Label бухгалтерия, управленческий учет, финансы предприятия appears 1006.0 times\n",
      "9  Label добыча сырья appears 49.0 times\n",
      "10  Label государственная служба, некоммерческие организации appears 44.0 times\n",
      "11  Label рабочий персонал appears 904.0 times\n",
      "12  Label наука, образование appears 322.0 times\n",
      "13  Label закупки appears 235.0 times\n",
      "14  Label автомобильный бизнес appears 613.0 times\n",
      "15  Label управление персоналом, тренинги appears 502.0 times\n",
      "16  Label транспорт, логистика appears 1123.0 times\n",
      "17  Label производство appears 1100.0 times\n",
      "18  Label туризм, гостиницы, рестораны appears 1457.0 times\n",
      "19  Label продажи appears 6373.0 times\n",
      "20  Label юристы appears 324.0 times\n",
      "21  Label банки, инвестиции, лизинг appears 1141.0 times\n",
      "22  Label административный персонал appears 2525.0 times\n",
      "23  Label начало карьеры, студенты appears 4356.0 times\n",
      "24  Label домашний персонал appears 119.0 times\n",
      "25  Label безопасность appears 204.0 times\n",
      "26  Label инсталляция и сервис appears 177.0 times\n",
      "27  Label искусство, развлечения, масс-медиа appears 430.0 times\n",
      "###\n",
      "As a mean 1.7824347826086957 species appear on each recording (standard deviation 0.9105016212332799)\n"
     ]
    }
   ],
   "source": [
    "counts = []\n",
    "for i in range(len(labels)):\n",
    "    print(i, ' Label {} appears {} times'.format(labels[i], np.sum(Y[:,i])))\n",
    "    counts.append(np.sum(Y[:,i]))\n",
    "print('###')\n",
    "all_sum_y = np.sum(Y, axis=1)\n",
    "print('As a mean {} species appear on each recording (standard deviation {})'.format(np.mean(all_sum_y), np.std(all_sum_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TXLpNbS5cnxS"
   },
   "outputs": [],
   "source": [
    "indexes = []\n",
    "labels_new = []\n",
    "counts_new = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if counts[i] > 300:\n",
    "        labels_new.append(labels[i])\n",
    "        counts_new.append(counts[i])\n",
    "        indexes.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "SkgH6rd6cnxW",
    "outputId": "8997da38-b3a8-4ecb-ae12-5d4ad9edeb45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['информационные технологии, интернет, телеком', 'строительство, недвижимость', 'спортивные клубы, фитнес, салоны красоты', 'маркетинг, реклама, pr', 'медицина, фармацевтика', 'консультирование', 'бухгалтерия, управленческий учет, финансы предприятия', 'рабочий персонал', 'наука, образование', 'автомобильный бизнес', 'управление персоналом, тренинги', 'транспорт, логистика', 'производство', 'туризм, гостиницы, рестораны', 'продажи', 'юристы', 'банки, инвестиции, лизинг', 'административный персонал', 'начало карьеры, студенты', 'искусство, развлечения, масс-медиа']\n",
      "\n",
      "[2463.0, 1276.0, 416.0, 1528.0, 777.0, 849.0, 1006.0, 904.0, 322.0, 613.0, 502.0, 1123.0, 1100.0, 1457.0, 6373.0, 324.0, 1141.0, 2525.0, 4356.0, 430.0]\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_new))\n",
    "print(labels_new)\n",
    "print()\n",
    "print(counts_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qd7tOKOd2fZt"
   },
   "outputs": [],
   "source": [
    "Y = Y[:, indexes]\n",
    "labels = labels_new\n",
    "counts = counts_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWFRvO1Df2d-"
   },
   "source": [
    "### Vectorize document from siquence of words to one vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "M6mgpTGKfzyF",
    "outputId": "a54f70b0-b715-4af4-bb6d-78cfb1a44b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22556, 300)\n",
      "(22556, 20)\n"
     ]
    }
   ],
   "source": [
    "X = [np.mean(i, axis=0) for i in X]\n",
    "X = np.array(X)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "956YiHMPYi9O"
   },
   "outputs": [],
   "source": [
    "\"\"\"w2v_weighted_data = {\"X\": X, \"Y\": Y, \"labels\": labels, \"counts\": counts}\n",
    "\n",
    "with open(\"w2v_weighted_tfidt.dat\", \"wb\") as ouf:\n",
    "  pickle.dump(w2v_weighted_data, ouf)\n",
    "  \n",
    "  \n",
    "files.download(\"w2v_weighted_tfidt.dat\")\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZBJIka6xEHL"
   },
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "835esZ1FxImr",
    "outputId": "fe7e5131-d8b7-4202-9feb-8556479c790a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12075, 1109782)\n",
      "(5175, 1109782)\n",
      "(12075, 20)\n",
      "(5175, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=100)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1MHfIbIxwxJ"
   },
   "source": [
    "### 1 vs All classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "OlSeW_WL2idD",
    "outputId": "8660d42f-59e9-49a9-8467-498deb245fe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5874949248883476, 4.994514106583072, 15.319711538461538, 4.170811518324608, 8.202059202059202, 7.506478209658422, 6.334990059642147, 7.049778761061947, 19.79192546583851, 10.396411092985318, 12.695219123505977, 5.674977738201247, 5.793636363636364, 4.374056280027454, 1.0, 19.669753086419753, 5.585451358457494, 2.523960396039604, 1.4630394857667586, 14.820930232558139]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "classes_weights = []\n",
    "max_count = max(counts_new)\n",
    "for i in range(len(counts_new)):\n",
    "    weight = max_count / counts_new[i] \n",
    "    classes_weights.append(weight)\n",
    "\n",
    "classes_weights = [classes_weights]  \n",
    "print(classes_weights) \n",
    "print(len(classes_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "cVZUQQrsxwdu",
    "outputId": "972ae90c-8e0e-4ccc-9661-a762c0f935f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for class  0 информационные технологии, интернет, телеком ... Weight for class = 5.825890333521763\n",
      "Training for class  1 строительство, недвижимость ... Weight for class = 12.298458149779735\n",
      "Training for class  2 спортивные клубы, фитнес, салоны красоты ... Weight for class = 40.07142857142857\n",
      "Training for class  3 маркетинг, реклама, pr ... Weight for class = 10.2012987012987\n",
      "Training for class  4 медицина, фармацевтика ... Weight for class = 21.527985074626866\n",
      "Training for class  5 консультирование ... Weight for class = 19.024875621890548\n",
      "Training for class  6 бухгалтерия, управленческий учет, финансы предприятия ... Weight for class = 15.473396998635744\n",
      "Training for class  7 рабочий персонал ... Weight for class = 17.295454545454547\n",
      "Training for class  8 наука, образование ... Weight for class = 49.52301255230125\n",
      "Training for class  9 автомобильный бизнес ... Weight for class = 27.68171021377672\n",
      "Training for class  10 управление персоналом, тренинги ... Weight for class = 31.90190735694823\n",
      "Training for class  11 транспорт, логистика ... Weight for class = 14.15056461731493\n",
      "Training for class  12 производство ... Weight for class = 14.131578947368421\n",
      "Training for class  13 туризм, гостиницы, рестораны ... Weight for class = 10.884842519685039\n",
      "Training for class  14 продажи ... Weight for class = 1.6833333333333333\n",
      "Training for class  15 юристы ... Weight for class = 51.27272727272727\n",
      "Training for class  16 банки, инвестиции, лизинг ... Weight for class = 13.925834363411619\n",
      "Training for class  17 административный персонал ... Weight for class = 5.723273942093541\n",
      "Training for class  18 начало карьеры, студенты ... Weight for class = 2.901453957996769\n",
      "Training for class  19 искусство, развлечения, масс-медиа ... Weight for class = 39.79391891891892\n",
      "CPU times: user 48 s, sys: 104 ms, total: 48.1 s\n",
      "Wall time: 48.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classif_list = []\n",
    "train_score_list, test_score_list = [], []\n",
    "\n",
    "# Training\n",
    "for i in range(len(labels)):\n",
    "  num_pos = np.sum(Y_train[:, i])\n",
    "  num_neg = len(Y_train[:, i]) - num_pos\n",
    "  sample_weights = np.ones(Y_train[:, i].shape)\n",
    "  sample_weights[Y_train[:, i] == 1] = num_neg / num_pos * 1\n",
    "  \n",
    "  y_train_for_label = Y_train[:, i]\n",
    "  new_classifier = LogisticRegression()\n",
    "  #new_classifier = RandomForestClassifier(n_estimators=80, max_depth=5)\n",
    "  #new_classifier = GradientBoostingClassifier(n_estimators=80, max_depth=3)\n",
    "  #new_classifier = GaussianNB()\n",
    "  #new_classifier = SVC()\n",
    "  #new_classifier = MLPClassifier()\n",
    "  new_classifier.fit(X_train, y_train_for_label, sample_weight=sample_weights)\n",
    "  classif_list.append(new_classifier)\n",
    "  #sample_weight=sample_weights\n",
    "  print(\"Training for class \", i, labels[i], \"... Weight for class =\", num_neg / num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "PvmMP2y6ysuP",
    "outputId": "548e7238-6085-434a-f0d6-74e387536071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Detecting информационные технологии, интернет, телеком with 77.9% f1-score (training 91.0%)\n",
      "1 Detecting строительство, недвижимость with 72.3% f1-score (training 88.3%)\n",
      "2 Detecting спортивные клубы, фитнес, салоны красоты with 69.0% f1-score (training 92.60000000000001%)\n",
      "3 Detecting маркетинг, реклама, pr with 64.4% f1-score (training 90.7%)\n",
      "4 Detecting медицина, фармацевтика with 77.3% f1-score (training 93.10000000000001%)\n",
      "5 Detecting консультирование with 39.5% f1-score (training 70.3%)\n",
      "6 Detecting бухгалтерия, управленческий учет, финансы предприятия with 63.2% f1-score (training 88.1%)\n",
      "7 Detecting рабочий персонал with 60.0% f1-score (training 82.39999999999999%)\n",
      "8 Detecting наука, образование with 59.9% f1-score (training 91.9%)\n",
      "9 Detecting автомобильный бизнес with 59.099999999999994% f1-score (training 87.0%)\n",
      "10 Detecting управление персоналом, тренинги with 61.4% f1-score (training 92.9%)\n",
      "11 Detecting транспорт, логистика with 68.89999999999999% f1-score (training 87.8%)\n",
      "12 Detecting производство with 54.6% f1-score (training 85.6%)\n",
      "13 Detecting туризм, гостиницы, рестораны with 80.80000000000001% f1-score (training 91.2%)\n",
      "14 Detecting продажи with 84.1% f1-score (training 90.3%)\n",
      "15 Detecting юристы with 60.9% f1-score (training 91.3%)\n",
      "16 Detecting банки, инвестиции, лизинг with 67.2% f1-score (training 87.2%)\n",
      "17 Detecting административный персонал with 67.2% f1-score (training 86.1%)\n",
      "18 Detecting начало карьеры, студенты with 59.599999999999994% f1-score (training 85.0%)\n",
      "19 Detecting искусство, развлечения, масс-медиа with 42.4% f1-score (training 88.7%)\n",
      "\n",
      "Mean f1 score: testing 0.6448500000000001, training 0.8807500000000001\n",
      "###\n",
      "Global accuracy: testing 0.9436135265700483, training 0.976463768115942\n",
      "Overall 7831 out of the 12075 training samples were well labeled\n",
      "Overall 1876 out of the 5175 testing samples were well labeled\n"
     ]
    }
   ],
   "source": [
    "# Test & display results\n",
    "for i in range(len(labels)):\n",
    "    classif = classif_list[i]\n",
    "    #train_score = float('{0:.3f}'.format(classif.score(X_train, Y_train[:,i])))\n",
    "    #test_score = float('{0:.3f}'.format(classif.score(X_test, Y_test[:,i])))\n",
    "    predict = classif.predict(X_train)\n",
    "    #predict = classif.predict(X_train.toarray())\n",
    "    train_score = float('{0:.3f}'.format(metrics.f1_score(Y_train[:,i], predict)))\n",
    "    predict = classif.predict(X_test)\n",
    "    #predict = classif.predict(X_test.toarray())\n",
    "    test_score = float('{0:.3f}'.format(metrics.f1_score(Y_test[:,i], predict)))\n",
    "    \n",
    "    train_score_list.append(train_score)\n",
    "    test_score_list.append(test_score)\n",
    "    print(i, 'Detecting {} with {}% f1-score (training {}%)'.format(labels[i],\n",
    "                                                                 100*test_score,\n",
    "                                                                 100*train_score))\n",
    "\n",
    "print()\n",
    "print('Mean f1 score: testing {}, training {}'.format(np.mean(test_score_list),\n",
    "                                                     np.mean(train_score_list)))\n",
    "    \n",
    "predict_train = np.zeros_like(Y_train)\n",
    "predict_test = np.zeros_like(Y_test)\n",
    "for i in range(len(labels)):\n",
    "    classif = classif_list[i]\n",
    "    predict_train[:,i] = classif.predict(X_train)\n",
    "    predict_test[:,i] = classif.predict(X_test)\n",
    "acc_train = 1 - np.sum(np.abs(predict_train - Y_train))/(Y_train.shape[0]*Y_train.shape[1])\n",
    "acc_test = 1 - np.sum(np.abs(predict_test - Y_test))/(Y_test.shape[0]*Y_test.shape[1])\n",
    "print('###')\n",
    "print('Global accuracy: testing {}, training {}'.format(acc_test, acc_train))\n",
    "\n",
    "well_labeled = 0\n",
    "for i in range(len(Y_train)):\n",
    "    if np.sum(np.abs(Y_train[i,:] - predict_train[i,:])) == 0:\n",
    "        well_labeled +=1\n",
    "print('Overall {} out of the {} training samples were well labeled'.format(well_labeled,len(Y_train)))\n",
    "\n",
    "well_labeled = 0\n",
    "for i in range(len(Y_test)):\n",
    "    if np.sum(np.abs(Y_test[i,:] - predict_test[i,:])) == 0:\n",
    "        well_labeled +=1\n",
    "\n",
    "print('Overall {} out of the {} testing samples were well labeled'.format(well_labeled,len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuN6Gs2n6-YB"
   },
   "source": [
    "## Try 1.\n",
    "### 3600 total samples. mean word2vec for document representation. 23 classes\n",
    "\n",
    "Log reg - Mean f1 score: testing 0.3923809523809524, training 0.4028095238095238\n",
    "\n",
    "Random forest (default) - Mean f1 score: testing 0.40671428571428575, training 0.9166666666666665\n",
    "\n",
    "Random forest (n_est=30, max_depth=3) - Mean f1 score: testing 0.48714285714285716, training 0.6254285714285716\n",
    "\n",
    "Random forest (n_est=30, max_depth=5) - Mean f1 score: testing 0.5288095238095236, training 0.8464285714285713\n",
    "\n",
    "Random forest (n_est=30, max_depth=7) - Mean f1 score: testing 0.5265238095238095, training 0.9252857142857144\n",
    "\n",
    "Random forest (n_est=30, max_depth=9) - Mean f1 score: testing 0.4854285714285715, training 0.9510952380952379\n",
    "\n",
    "Random forest (n_est=40, max_depth=5) - Mean f1 score: testing 0.5297619047619048, training 0.8522380952380951\n",
    "\n",
    "Random forest (n_est=60, max_depth=5) - Mean f1 score: testing 0.5395714285714286, training 0.8646190476190474\n",
    "\n",
    "Random forest (n_est=80, max_depth=5) - Mean f1 score: testing 0.5463809523809524, training 0.8645714285714287\n",
    "\n",
    "Random forest (n_est=100, max_depth=5) - Mean f1 score: testing 0.5424761904761906, training 0.866095238095238 \n",
    "\n",
    "Random forest (n_est=120, max_depth=5) - Mean f1 score: testing 0.5412857142857144, training 0.8694761904761905\n",
    "\n",
    "Random forest (n_est=150, max_depth=5) - Mean f1 score: testing 0.5402380952380953, training 0.8681428571428571\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=80, max_depth=5) - Mean f1 score: testing 0.5571904761904762, training 0.9752380952380952 / time = 3 min\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=80, max_depth=4) - Mean f1 score: testing 0.5720476190476189, training 0.9719047619047619 \n",
    "\n",
    "GradientBoostingClassifier(n_estimators=80, max_depth=3)  - Mean f1 score: testing 0.5788095238095239, training 0.9293809523809523 / time = 2 min -----------\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=80, max_depth=2) - Mean f1 score: testing 0.5351904761904761, training 0.7915238095238095 / time 2 min\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=30, max_depth=3) - Mean f1 score: testing 0.5093809523809524, training 0.7613333333333333  / time 2 min\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=100, max_depth=3) - Mean f1 score: testing 0.5757142857142857, training 0.949190476190476\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=50, max_depth=3) - Mean f1 score: testing 0.5532380952380953, training 0.8664761904761905\n",
    "\n",
    "GaussianNB() - Mean f1 score: testing 0.35142857142857153, training 0.36628571428571427\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jk740ZgTIQUe"
   },
   "source": [
    "## Try 2.\n",
    "### 10000 total samples. tf-idf for document representation. 20 classes\n",
    "\n",
    "Log reg - Mean f1 score: testing 0.6833, training 0.8485000000000001 / time=5s ----------\n",
    "\n",
    "Log reg(weights_for_positive * 0.5) - Mean f1 score: testing 0.70085, training 0.8743000000000001 -----------------\n",
    "\n",
    "RandomForestClassifier(n_estimators=80, max_depth=5) - Mean f1 score: testing 0.57405, training 0.68235\n",
    "\n",
    "GaussianNB() - Mean f1 score: testing 0.4888, training 0.8202 / time=2min, long predict time\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=80, max_depth=3) - Mean f1 score: testing 0.60145, training 0.7172499999999999  / time=8min\n",
    "\n",
    "### 10000 samples. mean word2vec for document representation\n",
    "\n",
    "Log rer - Mean f1 score: testing 0.44904999999999984, training 0.45100000000000007\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=80, max_depth=3) - Mean f1 score: testing 0.6090000000000001, training 0.7715 / time=5min\n",
    "\n",
    "### 10000 samples. mean word2vec weighted by tf-idf\n",
    "\n",
    "Lof reg -Mean f1 score: testing 0.37105, training 0.3703\n",
    "\n",
    "RandomForestClassifier(n_estimators=80, max_depth=5) - Mean f1 score: testing 0.5995000000000001, training 0.7244\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=80, max_depth=3) - Mean f1 score: testing 0.6052, training 0.7688 /time=5min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeF3l3tc8qbx"
   },
   "source": [
    "## Try 3\n",
    "### 22000 samples. tfidf.\n",
    "Log ref - Mean f1 score: testing 0.6993, training 0.8241499999999998\n",
    "\n",
    "### 22_000 samples. word2ver mean\n",
    "\n",
    "Log reg  - Mean f1 score: testing 0.46375, training 0.472\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=80, max_depth=3) - \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A75eRS5RP_91"
   },
   "source": [
    "## Try 4\n",
    "### 22000 samples. tf-idf + n_gramms \n",
    "#### n_gramms=(1, 2)\n",
    "\n",
    "Log Reg  - Mean f1 score: testing 0.7274999999999999, training 0.8892999999999999  / 1 min  ----------------\n",
    "\n",
    "Log reg(weights_for_positive * 0.5) - Mean f1 score: testing 0.7292500000000001, training 0.9058999999999999 / 1 min ----------\n",
    "\n",
    "Log reg(weights_for_positive * 0.7) -  Mean f1 score: testing 0.73125, training 0.89955 --------------\n",
    "\n",
    "Log reg(weights_for_positive * 0.8) - Mean f1 score: testing 0.73075, training 0.8967500000000002\n",
    "\n",
    "#### n_gramms=(1, 3)\n",
    "Log reg - Mean f1 score: testing 0.72385, training 0.9073499999999999 / 2min\n",
    "\n",
    "Log reg  (C=0.8)Mean f1 score: testing 0.7222000000000001, training 0.9015000000000001 /2min\n",
    "\n",
    "Log reg(weights_for_positive * 0.7) - Mean f1 score: testing 0.71845, training 0.915050000000000 /2min\n",
    "\n",
    "#### n_gramms= (1, 4)\n",
    "log reg - Mean f1 score: testing 0.71125, training 0.9154000000000002  / 4min\n",
    "\n",
    "log reg(c=0.9) - Mean f1 score: testing 0.7111000000000001, training 0.91395 /4min\n",
    "\n",
    "### 25000 samples. tf-idf + n_gramms\n",
    "####n_gramms=(1, 2)\n",
    "\n",
    "Log reg - Mean f1 score: testing 0.7184, training 0.8848499999999999 /1min\n",
    "\n",
    "Log reg(weights_for_positive * 0.5) - Mean f1 score: testing 0.7205, training 0.9047000000000001  /1min\n",
    "\n",
    "Log reg(weights_for_positive * 0.7) - Mean f1 score: testing 0.7187500000000001, training 0.8970500000000001\n",
    "\n",
    "Log reg(weights_for_positive * 1.5)  - Mean f1 score: testing 0.70785, training 0.8615\n",
    "\n",
    "Log reg(weights_for_positive * 1.2)  - Mean f1 score: testing 0.715, training 0.8753500000000001\n",
    "\n",
    "Log reg(weights_for_positive * 0.9)  -  Mean f1 score: testing 0.7190999999999999, training 0.8894500000000001\n",
    "\n",
    "#### without n_gramm\n",
    "\n",
    "Log reg - Mean f1 score: testing 0.6983499999999999, training 0.8177999999999999\n",
    "\n",
    "\n",
    "#### .....\n",
    "#### n_gramms=(1, 2)\n",
    "\n",
    "Log reg - Mean f1 score: testing 0.6512, training 0.89055\n",
    "\n",
    "Log reg(weights_for_positive * 0.5) - Mean f1 score: testing 0.62905, training 0.9113499999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Jn1p9aiKM4CI",
    "aBXRwF2Wz3e3",
    "FWFRvO1Df2d-",
    "mRR01c-_29F6"
   ],
   "name": "classification4_to_binary_tasks.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
